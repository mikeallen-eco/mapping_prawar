---
title: "The 'Mapping Warbler Song' Project"
author: "Mike Allen"
date: "April 2023"
output: html_document
---
# Load libraries and read in your data file
This code file is organized into discrete "chunks" each of which can be run by clicking its green arrow. Make sure there is only one csv file (the csv  downloaded from Macaulay Library) in the "prawar_data" folder. This code reads in the data, keeping only songs with a known location (latitude/longitude), from June or July, and with a quality score of 3 or greater.
```{r}
# load the function libraries called "dplyr", "ggplot2", and "sf"
# note: this also installs them if they are not yet installed
if (require("dplyr") == F) {
  install.packages("dplyr")
}
if (require("ggplot2") == F) {
  install.packages("ggplot2")
}
if (require("sf") == F) {
  install.packages("sf")
}

library(dplyr)
library(ggplot2)
library(sf)

# read in the data from your "prawar_data" folder
# this selects just the data from the main part of their range
      # with a quality rating of 3 or above
      # and that occur in the months of June or July

# get the name of the raw data file
data_file <-
  list.files("prawar_data")[grepl(list.files("prawar_data"),
                                  pattern = ".csv")]

# load and filter the raw data file
my_data <- read.csv(paste0("prawar_data/", data_file)) %>%
    filter(Average.Community.Rating >= 3,
           is.na(Latitude) != TRUE,
           Latitude > 30,
           Longitude > -98,
           Month %in% c(6,7)) %>%
    rename(cat_num = 1)

# load the map of North America
state_bounds <- readRDS("map_data/prawar_map.rds")
```
# View and explore the filtered raw data
QUESTION 1: How many song recordings (rows) and data fields (columns) does it have?
```{r}
View(my_data)
```
# Make a rough map of the raw data
QUESTION 2: Where are most of the song locations concentrated geographically?
```{r}
my_data %>%
    ggplot() +
  geom_sf(data = state_bounds, aes(), color = "gray",
          size = .25) +
  geom_point(aes(x = Longitude, y = Latitude), 
                 size = 1,
                 color = "firebrick", 
            alpha = .5) +
  theme_bw() + 
  theme(text = element_text(size = 14)) +
  labs(x = "", y = "")
```
# calculate number of latitude bands your data spans
QUESTION 3: Which latitude band has the most song recordings?
QUESTION 4: Which state has the most song recordings?
```{r}
# print how many latitude and longitude bands the dataset covers
length(unique(floor(my_data$Latitude)))
length(unique(floor(my_data$Longitude)))

# print how many songs are in each latitude or longitude band
table(floor(my_data$Latitude))
table(floor(my_data$Longitude))

#print how many song recordings are available for each state
table(my_data$State)
```
# Create final the data file
TO RUN THE CHUNK BELOW, FIRST CHANGE THE GROUP NAME AND SONG NUMBERS TO MATCH YOUR GROUP. 

For example if you name is "warblrz" and your assigned song numbers are 201-250, then change "group_name" to "warblrz" and 1:50 to 201:250. 

Then, hit the green arrow to run this code and create a final blank data file for you to fill out. Once you do this, move the newly-created file from the "my_output" folder to the "my_data" folder.
```{r}
# WHAT IS YOUR GROUP NAME? (keep it short, no spaces allowed)
# AND WHAT SONG NUMBERS WERE YOU ASSIGNED TO MEASURE?
  # change the xx-xx to those numbers (e.g., 1:50)
my_group_name <- "group_name"
my_song_numbers <- 1:50

# create a randomized data set tt
my_data_final <- my_data %>%
  mutate(song_num = 1:nrow(my_data)) %>%
  filter(song_num %in% my_song_numbers) %>%
  select(cat_num, Latitude, Longitude, 
         quality = Average.Community.Rating) %>%
  mutate(link = paste0("https://macaulaylibrary.org/asset/", 
                       cat_num),
         num_syllables = "", 
         freq_range_mm = "",
         two_khz_mm = "",
         duration_mm = "",
         two_sec_mm = "",
         skip_notes = ""
)

# write the final "blank" data file to a csv file in the "my_output" folder

write.csv(my_data_final, 
          paste0("my_output/", my_group_name, 
                 "_", min(my_song_numbers),
                 "_", max(my_song_numbers),
                 "_data_file.csv"),
          row.names = F)

# create a "my_data" folder if none exists
if(!dir.exists("my_data")){dir.create("my_data")}

```
# Making your measurements
Now that we've made our data sheet, we can go and collect some data. Minimize RStudio, go back to the README file (https://github.com/mikeallen-eco/mapping_warbler/blob/main/README.md), and complete steps 9-13. In those steps, you'll use spreadsheet software to open the data sheet file you just created. Then, you'll go to each link, view the sonogram, and make the measurements using a ruler or visual observation. (See README file for more info.) You'll add those measurements to your data file and, when you're done, send in the results so I can compile the course data.

In steps 14+ we'll use the mapping_prawar2.Rmd file to map the results.